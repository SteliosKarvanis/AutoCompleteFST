{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before run this notebook:\n",
    "-  Build the project first\n",
    "```bash\n",
    "mkdir build\n",
    "cd build\n",
    "cmake ..\n",
    "make test\n",
    "```\n",
    "- And move this notebook to the bin folder\n",
    "```bash\n",
    "mv test.ipynb ../bin\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "with open(\"../data/american-english-sorted\", 'r') as f:\n",
    "    for word in f.readlines():\n",
    "        words.append(word.replace('\\n', ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate random prefixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefixes = []\n",
    "for word in random.sample(words, num_samples):\n",
    "    while(len(word) < 2):\n",
    "        word = random.choice(words)\n",
    "    rand_int = random.randint(1, len(word)-1)\n",
    "    prefix = word[:rand_int]\n",
    "    prefixes.append(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['forbi', 'sabotage', 'symptom', 'damson', 'Flemi']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefixes[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate random prefixes with a fix length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random(prefix_len: int):\n",
    "    while True:\n",
    "        word = random.choice(words)\n",
    "        if len(word) >= prefix_len:\n",
    "            break\n",
    "    return word[:prefix_len]\n",
    "\n",
    "def get_result(prefix: str):\n",
    "    return [x for x in words if x.startswith(prefix)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "demi\n",
      "['demigod', \"demigod's\", 'demigods', 'demijohn', \"demijohn's\", 'demijohns', 'demilitarization', \"demilitarization's\", 'demilitarize', 'demilitarized', 'demilitarizes', 'demilitarizing', 'demise', \"demise's\", 'demised', 'demises', 'demising', 'demitasse', \"demitasse's\", 'demitasses']\n"
     ]
    }
   ],
   "source": [
    "prefix = get_random(prefix_len=4)\n",
    "results = get_result(prefix)\n",
    "print(prefix) \n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cpp_results(text: str):\n",
    "    program_path = './test_autocomplete'\n",
    "    arguments = [text]\n",
    "    subprocess.run([program_path] + arguments, text=True, capture_output=True)\n",
    "    with open(\"output_autocomplete.txt\", 'r') as f:\n",
    "        result = [x.replace('\\n', '') for x in f.readlines()]\n",
    "    return result\n",
    "\n",
    "def get_expected_results(text):\n",
    "    return [x for x in words if x.startswith(text)]\n",
    "\n",
    "def check(text):\n",
    "    return get_cpp_results(text) == get_expected_results(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check('lamasae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking forbi\n",
      "Checking sabotage\n",
      "Checking symptom\n",
      "Checking damson\n",
      "Checking Flemi\n",
      "Checking Mash\n",
      "Checking Franc\n",
      "Checking telecon\n",
      "Checking Mes\n",
      "Checking port\n",
      "Checking stamen\n",
      "Checking upgrad\n",
      "Checking Tweedl\n",
      "Checking ten\n",
      "Checking Galv\n",
      "Checking thi\n",
      "Checking ki\n",
      "Checking Strindberg'\n",
      "Checking puckere\n",
      "Checking analo\n"
     ]
    }
   ],
   "source": [
    "for prefix in prefixes[:20]:\n",
    "    print(f\"Checking {prefix}\")\n",
    "    if not check(prefix):\n",
    "        raise Exception(f\"Failed for {prefix}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Levestein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textdistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieve_levestein_dist = textdistance.levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def levestein(text, max_dist):\n",
    "    output = []\n",
    "    for word in words:\n",
    "        dist = retrieve_levestein_dist(word, text)\n",
    "        if dist <= max_dist:\n",
    "            output.append(word)\n",
    "    return output\n",
    "\n",
    "def get_cpp_levestein_results(text: str, dist: int):\n",
    "    program_path = './test_levestein'\n",
    "    arguments = [text, str(dist)]\n",
    "    subprocess.run([program_path] + arguments, text=True, capture_output=True)\n",
    "    with open(\"output_levestein.txt\", 'r') as f:\n",
    "        result = [x.replace('\\n', '') for x in f.readlines()]\n",
    "    result.sort()\n",
    "    return result\n",
    "\n",
    "def check_levestein(text, dist):\n",
    "    return get_cpp_levestein_results(text, dist) == levestein(text, dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AA', 'AAA', 'AMA', 'FAA']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_cpp_levestein_results(\"AAA\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AA', 'AAA', 'AMA', 'FAA']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "levestein(\"AAA\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_levestein(\"AAA\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [delete , add, replace, maintain]\n",
    "maintain = 0.9\n",
    "others = (1 - maintain)/3\n",
    "porcentages = [others, others, others, maintain]\n",
    "assert sum(porcentages) == 1\n",
    "accumulated = 0\n",
    "intervals = []\n",
    "for porcentage in porcentages:\n",
    "    accumulated += porcentage\n",
    "    intervals.append(accumulated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action(number: float):\n",
    "    output = 0\n",
    "    while number > intervals[output]:\n",
    "        output += 1\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_levestein = []\n",
    "originals = []\n",
    "for word in random.sample(words, num_samples):\n",
    "    curr_word = \"\"\n",
    "    curr_char_idx = 0\n",
    "    while curr_char_idx != len(word):\n",
    "        action = get_action(random.uniform(0, 1))\n",
    "        # Delete char\n",
    "        if action == 0:\n",
    "            curr_char_idx += 1\n",
    "        # Add random char\n",
    "        elif action == 1:\n",
    "            random_char = random.choice(string.ascii_letters)\n",
    "            curr_word += random_char\n",
    "        # Replace char\n",
    "        elif action == 2:\n",
    "            random_char = random.choice(string.ascii_letters)\n",
    "            curr_word += random_char\n",
    "            curr_char_idx += 1\n",
    "        # Maintain char\n",
    "        elif action == 3:\n",
    "            curr_word += word[curr_char_idx]\n",
    "            curr_char_idx += 1\n",
    "    words_levestein.append(curr_word)\n",
    "    originals.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"spxout's\", \"spout's\")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = 1\n",
    "words_levestein[index], originals[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = []\n",
    "for word in words_levestein[:100]:\n",
    "    # print(f\"Checking {word}\")\n",
    "    for dist in range(4):\n",
    "        if not check_levestein(word, dist):\n",
    "            print(f\"Failed for {word} and {dist}\")\n",
    "            errors.append((word, dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "word, dist = \"musOrroom\", 2\n",
    "cpp_res = get_cpp_levestein_results(word, dist)\n",
    "real_res = levestein(word, dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('musOrroom', [])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word, [x for x in real_res if x not in cpp_res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ita",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
