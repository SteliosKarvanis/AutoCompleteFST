{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before run this notebook:\n",
    "-  Build the project first\n",
    "```bash\n",
    "mkdir build\n",
    "cd build\n",
    "cmake ..\n",
    "make test\n",
    "```\n",
    "- And move this notebook to the bin folder\n",
    "```bash\n",
    "mv test.ipynb ../bin\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "with open(\"../data/american-english-sorted\", 'r') as f:\n",
    "    for word in f.readlines():\n",
    "        words.append(word.replace('\\n', ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate random prefixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefixes = []\n",
    "for word in random.sample(words, num_samples):\n",
    "    while(len(word) < 2):\n",
    "        word = random.choice(words)\n",
    "    rand_int = random.randint(1, len(word)-1)\n",
    "    prefix = word[:rand_int]\n",
    "    prefixes.append(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['co', 'iceb', 'Malayala', 'ocari', 'end']"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefixes[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate random prefixes with a fix length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random(prefix_len: int):\n",
    "    while True:\n",
    "        word = random.choice(words)\n",
    "        if len(word) >= prefix_len:\n",
    "            break\n",
    "    return word[:prefix_len]\n",
    "\n",
    "def get_result(prefix: str):\n",
    "    return [x for x in words if x.startswith(prefix)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depr\n",
      "['deprave', 'depraved', 'depraves', 'depraving', 'depravities', 'depravity', \"depravity's\", 'deprecate', 'deprecated', 'deprecates', 'deprecating', 'deprecation', \"deprecation's\", 'deprecatory', 'depreciate', 'depreciated', 'depreciates', 'depreciating', 'depreciation', \"depreciation's\", 'depredation', \"depredation's\", 'depredations', 'depress', 'depressant', \"depressant's\", 'depressants', 'depressed', 'depresses', 'depressing', 'depressingly', 'depression', \"depression's\", 'depressions', 'depressive', \"depressive's\", 'depressives', 'deprivation', \"deprivation's\", 'deprivations', 'deprive', 'deprived', 'deprives', 'depriving', 'deprogram', 'deprogramed', 'deprograming', 'deprogrammed', 'deprogramming', 'deprograms']\n"
     ]
    }
   ],
   "source": [
    "prefix = get_random(prefix_len=4)\n",
    "results = get_result(prefix)\n",
    "print(prefix) \n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cpp_results(text: str):\n",
    "    program_path = './test_autocomplete'\n",
    "    arguments = [text]\n",
    "    subprocess.run([program_path] + arguments, text=True, capture_output=True)\n",
    "    with open(\"output_autocomplete.txt\", 'r') as f:\n",
    "        result = [x.replace('\\n', '') for x in f.readlines()]\n",
    "    return result\n",
    "\n",
    "def get_expected_results(text):\n",
    "    return [x for x in words if x.startswith(text)]\n",
    "\n",
    "def check(text):\n",
    "    return get_cpp_results(text) == get_expected_results(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check('lamasae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking co\n",
      "Checking iceb\n",
      "Checking Malayala\n",
      "Checking ocari\n",
      "Checking end\n",
      "Checking waxw\n",
      "Checking terro\n",
      "Checking ad\n",
      "Checking stiffnes\n",
      "Checking f\n",
      "Checking C\n",
      "Checking Mosu\n",
      "Checking reject\n",
      "Checking corpu\n",
      "Checking operation'\n",
      "Checking consu\n",
      "Checking hou\n",
      "Checking Norse\n",
      "Checking L\n",
      "Checking comm\n"
     ]
    }
   ],
   "source": [
    "for prefix in prefixes[:20]:\n",
    "    print(f\"Checking {prefix}\")\n",
    "    if not check(prefix):\n",
    "        raise Exception(f\"Failed for {prefix}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Levestein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textdistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieve_levestein_dist = textdistance.levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def levestein(text, max_dist):\n",
    "    output = []\n",
    "    for word in words:\n",
    "        dist = retrieve_levestein_dist(word, text)\n",
    "        if dist <= max_dist:\n",
    "            output.append(word)\n",
    "    return output\n",
    "\n",
    "def get_cpp_levestein_results(text: str, dist: int):\n",
    "    program_path = './test_levestein'\n",
    "    arguments = [text, str(dist)]\n",
    "    subprocess.run([program_path] + arguments, text=True, capture_output=True)\n",
    "    with open(\"output_levestein.txt\", 'r') as f:\n",
    "        result = [x.replace('\\n', '') for x in f.readlines()]\n",
    "    result.sort()\n",
    "    return result\n",
    "\n",
    "def check_levestein(text, dist):\n",
    "    return get_cpp_levestein_results(text, dist) == levestein(text, dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AA', 'AAA', 'AMA', 'FAA']"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_cpp_levestein_results(\"AAA\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AA', 'AAA', 'AMA', 'FAA']"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "levestein(\"AAA\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_levestein(\"AAA\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.033333333333333326, 0.06666666666666665, 0.09999999999999998, 1.0]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [delete , add, replace, maintain]\n",
    "maintain = 0.9\n",
    "others = (1 - maintain)/3\n",
    "porcentages = [others, others, others, maintain]\n",
    "assert sum(porcentages) == 1\n",
    "accumulated = 0\n",
    "intervals = []\n",
    "for porcentage in porcentages:\n",
    "    accumulated += porcentage\n",
    "    intervals.append(accumulated)\n",
    "intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action(number: float):\n",
    "    output = 0\n",
    "    while number > intervals[output]:\n",
    "        output += 1\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_action(random.uniform(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_levestein = []\n",
    "originals = []\n",
    "for word in random.sample(words, num_samples):\n",
    "    curr_word = \"\"\n",
    "    curr_char_idx = 0\n",
    "    while curr_char_idx != len(word):\n",
    "        action = get_action(random.uniform(0, 1))\n",
    "        # Delete char\n",
    "        if action == 0:\n",
    "            curr_char_idx += 1\n",
    "        # Add random char\n",
    "        elif action == 1:\n",
    "            random_char = random.choice(string.ascii_letters)\n",
    "            curr_word += random_char\n",
    "        # Replace char\n",
    "        elif action == 2:\n",
    "            random_char = random.choice(string.ascii_letters)\n",
    "            curr_word += random_char\n",
    "            curr_char_idx += 1\n",
    "        # Maintain char\n",
    "        elif action == 3:\n",
    "            curr_word += word[curr_char_idx]\n",
    "            curr_char_idx += 1\n",
    "    words_levestein.append(curr_word)\n",
    "    originals.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('optionallYy', 'optionally')"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = 1\n",
    "words_levestein[index], originals[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed for malaise's and 3\n",
      "Failed for shits and 3\n",
      "Failed for walk and 3\n",
      "Failed for hoe and 2\n",
      "Failed for hoe and 3\n",
      "Failed for He and 2\n",
      "Failed for He and 3\n"
     ]
    }
   ],
   "source": [
    "errors = []\n",
    "for word in words_levestein[:20]:\n",
    "    # print(f\"Checking {word}\")\n",
    "    for dist in range(4):\n",
    "        if not check_levestein(word, dist):\n",
    "            print(f\"Failed for {word} and {dist}\")\n",
    "            errors.append((word, dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "word, dist = errors[0]\n",
    "cpp_res = get_cpp_levestein_results(word, dist)\n",
    "real_res = levestein(word, dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"malaise's\""
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"HÃ©loise's\"]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in real_res if x not in cpp_res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ita",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
