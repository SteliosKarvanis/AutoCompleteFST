{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "import subprocess\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "with open(\"data/american-english-sorted\", 'r') as f:\n",
    "    for word in f.readlines():\n",
    "        words.append(word.replace('\\n', ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate random prefixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefixes = []\n",
    "for word in random.sample(words, num_samples):\n",
    "    while(len(word) < 2):\n",
    "        word = random.choice(words)\n",
    "    rand_int = random.randint(1, len(word)-1)\n",
    "    prefix = word[:rand_int]\n",
    "    prefixes.append(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"examples.txt\", \"w\") as f:\n",
    "    for x in prefixes:\n",
    "        f.write(x)\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ken', 'wi', 'in', 'six', 'Cha']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefixes[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate random prefixes with a fix length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random(prefix_len: int):\n",
    "    while True:\n",
    "        word = random.choice(words)\n",
    "        if len(word) >= prefix_len:\n",
    "            break\n",
    "    return word[:prefix_len]\n",
    "\n",
    "def get_result(prefix: str):\n",
    "    return [x for x in words if x.startswith(prefix)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orth\n",
      "['orthodontia', \"orthodontia's\", 'orthodontic', 'orthodontics', \"orthodontics's\", 'orthodontist', \"orthodontist's\", 'orthodontists', 'orthodox', 'orthodoxies', 'orthodoxy', \"orthodoxy's\", 'orthogonal', 'orthogonality', 'orthographic', 'orthographies', 'orthography', \"orthography's\", 'orthopaedic', 'orthopaedics', \"orthopaedics's\", 'orthopaedist', \"orthopaedist's\", 'orthopaedists', 'orthopedic', 'orthopedics', \"orthopedics's\", 'orthopedist', \"orthopedist's\", 'orthopedists']\n"
     ]
    }
   ],
   "source": [
    "prefix = get_random(prefix_len=4)\n",
    "results = get_result(prefix)\n",
    "print(prefix) \n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cpp_results(text: str):\n",
    "    os.chdir(\"bin\")\n",
    "    program_path = './autocomplete'\n",
    "    arguments = [text]\n",
    "    subprocess.run([program_path] + arguments, text=True, capture_output=True)\n",
    "    with open(\"output_autocomplete.txt\", 'r') as f:\n",
    "        result = [x.replace('\\n', '') for x in f.readlines()]\n",
    "    os.chdir(\"..\")\n",
    "    return result\n",
    "\n",
    "def get_expected_results(text):\n",
    "    return [x for x in words if x.startswith(text)]\n",
    "\n",
    "def check_autocomplete(text):\n",
    "    return get_cpp_results(text) == get_expected_results(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_autocomplete('lamasae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Ken\n",
      "Checking wi\n",
      "Checking in\n",
      "Checking six\n",
      "Checking Cha\n",
      "Checking u\n",
      "Checking shirk\n",
      "Checking dev\n",
      "Checking spr\n",
      "Checking collision\n",
      "Checking all\n",
      "Checking ove\n",
      "Checking doo\n",
      "Checking hosan\n",
      "Checking licor\n",
      "Checking separat\n",
      "Checking se\n",
      "Checking ridge\n",
      "Checking gen\n",
      "Checking pa\n"
     ]
    }
   ],
   "source": [
    "for prefix in prefixes[:20]:\n",
    "    print(f\"Checking {prefix}\")\n",
    "    if not check_autocomplete(prefix):\n",
    "        raise Exception(f\"Failed for {prefix}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bin_search_results(text: str):\n",
    "    os.chdir(\"bin\")\n",
    "    program_path = './binary_search'\n",
    "    arguments = [text]\n",
    "    subprocess.run([program_path] + arguments)\n",
    "    with open(\"output_bin_search.txt\", 'r') as f:\n",
    "        result = [x.replace('\\n', '') for x in f.readlines()]\n",
    "    os.chdir(\"..\")\n",
    "    return result\n",
    "\n",
    "def check_bin_search(text):\n",
    "    return get_bin_search_results(text) == get_expected_results(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Ken\n",
      "Checking wi\n",
      "Checking in\n",
      "Checking six\n",
      "Checking Cha\n",
      "Checking u\n",
      "Checking shirk\n",
      "Checking dev\n",
      "Checking spr\n",
      "Checking collision\n",
      "Checking all\n",
      "Checking ove\n",
      "Checking doo\n",
      "Checking hosan\n",
      "Checking licor\n",
      "Checking separat\n",
      "Checking se\n",
      "Checking ridge\n",
      "Checking gen\n",
      "Checking pa\n",
      "Checking rel\n",
      "Checking mong\n",
      "Checking ma\n",
      "Checking si\n",
      "Checking fuz\n",
      "Checking underworl\n",
      "Checking interloc\n",
      "Checking freigh\n",
      "Checking Marva'\n",
      "Checking i\n",
      "Checking In\n",
      "Checking condition'\n",
      "Checking Claudin\n",
      "Checking J\n",
      "Checking Pytha\n",
      "Checking cheapl\n",
      "Checking disciplin\n",
      "Checking defamat\n",
      "Checking tercenten\n",
      "Checking teapot\n",
      "Checking r\n",
      "Checking ba\n",
      "Checking initia\n",
      "Checking engi\n",
      "Checking a\n",
      "Checking t\n",
      "Checking im\n",
      "Checking ambulato\n",
      "Checking Nor\n",
      "Checking rigmaro\n",
      "Checking nuisance'\n",
      "Checking Acru\n",
      "Checking UT'\n",
      "Checking Agustin'\n",
      "Checking em\n",
      "Checking ap\n",
      "Checking dat\n",
      "Checking e\n",
      "Checking pander\n",
      "Checking Heisenberg\n",
      "Checking dunn\n",
      "Checking Trum\n",
      "Checking wo\n",
      "Checking s\n",
      "Checking dr\n",
      "Checking fleecin\n",
      "Checking prett\n",
      "Checking spr\n",
      "Checking Sa\n",
      "Checking hoopl\n",
      "Checking b\n",
      "Checking bre\n",
      "Checking sodom\n",
      "Checking abatto\n",
      "Checking cr\n",
      "Checking acron\n",
      "Checking Mar\n",
      "Checking lu\n",
      "Checking c\n",
      "Checking sn\n",
      "Checking Fairho\n",
      "Checking elliptic\n",
      "Checking sci\n",
      "Checking mart\n",
      "Checking h\n",
      "Checking larcen\n",
      "Checking sne\n",
      "Checking lawyer\n",
      "Checking tag\n",
      "Checking ove\n",
      "Checking sequi\n",
      "Checking c\n",
      "Checking luxuriat\n",
      "Checking Gro\n",
      "Checking S\n",
      "Checking Kris\n",
      "Checking Pope'\n",
      "Checking M\n",
      "Checking exten\n",
      "Checking degener\n",
      "Checking Neo\n",
      "Checking fe\n",
      "Checking disinteres\n",
      "Checking pe\n",
      "Checking fina\n",
      "Checking ph\n",
      "Checking lique\n",
      "Checking brai\n",
      "Checking pre\n",
      "Checking wordie\n",
      "Checking mo\n",
      "Checking abstracti\n",
      "Checking s\n",
      "Checking ch\n",
      "Checking house\n",
      "Checking Columb\n",
      "Checking stu\n",
      "Checking nos\n",
      "Checking sm\n",
      "Checking beho\n",
      "Checking Hayn\n",
      "Checking defe\n",
      "Checking fo\n",
      "Checking u\n",
      "Checking muta\n",
      "Checking percepti\n",
      "Checking Darnell'\n",
      "Checking ker\n",
      "Checking exo\n",
      "Checking K\n",
      "Checking Mess\n",
      "Checking slove\n",
      "Checking thesauru\n",
      "Checking sno\n",
      "Checking glockens\n",
      "Checking qua\n",
      "Checking discar\n",
      "Checking hardbac\n",
      "Checking thre\n",
      "Checking A\n",
      "Checking warf\n",
      "Checking m\n",
      "Checking stru\n",
      "Checking c\n",
      "Checking wea\n",
      "Checking ra\n",
      "Checking stickleb\n",
      "Checking n\n",
      "Checking styl\n",
      "Checking sy\n",
      "Checking dissol\n",
      "Checking cod\n",
      "Checking lasciv\n",
      "Checking r\n",
      "Checking tsarin\n",
      "Checking guru'\n",
      "Checking orga\n",
      "Checking pais\n",
      "Checking ukul\n",
      "Checking e\n",
      "Checking gu\n",
      "Checking falterin\n",
      "Checking scholar\n",
      "Checking ob\n",
      "Checking bu\n",
      "Checking jers\n",
      "Checking pala\n",
      "Checking brea\n",
      "Checking mech\n",
      "Checking Lee\n",
      "Checking play'\n",
      "Checking unc\n",
      "Checking stav\n",
      "Checking knight\n",
      "Checking essayist\n",
      "Checking haf\n",
      "Checking typ\n",
      "Checking Konrad\n",
      "Checking spe\n",
      "Checking me\n",
      "Checking convey\n",
      "Checking cosm\n",
      "Checking TNT\n",
      "Checking d\n",
      "Checking disten\n",
      "Checking Ear\n",
      "Checking du\n",
      "Checking muck\n",
      "Checking a\n",
      "Checking Ben\n",
      "Checking chastenin\n",
      "Checking circum\n",
      "Checking dec\n",
      "Checking magnification\n",
      "Checking abn\n",
      "Checking spitba\n",
      "Checking vomi\n",
      "Checking re\n",
      "Checking Ea\n",
      "Checking patron\n"
     ]
    }
   ],
   "source": [
    "for prefix in prefixes[:200]:\n",
    "    print(f\"Checking {prefix}\")\n",
    "    if not check_bin_search(prefix):\n",
    "        raise Exception(f\"Failed for {prefix}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Levestein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textdistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieve_levestein_dist = textdistance.levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def levestein(text, max_dist):\n",
    "    output = []\n",
    "    for word in words:\n",
    "        dist = retrieve_levestein_dist(word, text)\n",
    "        if dist <= max_dist:\n",
    "            output.append(word)\n",
    "    return output\n",
    "\n",
    "def get_cpp_levestein_results(text: str, dist: int):\n",
    "    os.chdir(\"bin\")\n",
    "    program_path = './levestein'\n",
    "    arguments = [text, str(dist)]\n",
    "    subprocess.run([program_path] + arguments, text=True, capture_output=True)\n",
    "    with open(\"output_levestein.txt\", 'r') as f:\n",
    "        result = [x.replace('\\n', '') for x in f.readlines()]\n",
    "    result.sort()\n",
    "    os.chdir(\"..\")\n",
    "    return result\n",
    "\n",
    "def check_levestein(text, dist):\n",
    "    return get_cpp_levestein_results(text, dist) == levestein(text, dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_cpp_levestein_results(\"AAA\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "levestein(\"AAA\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_levestein(\"AAA\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [delete , add, replace, maintain]\n",
    "maintain = 0.9\n",
    "others = (1 - maintain)/3\n",
    "porcentages = [others, others, others, maintain]\n",
    "assert sum(porcentages) == 1\n",
    "accumulated = 0\n",
    "intervals = []\n",
    "for porcentage in porcentages:\n",
    "    accumulated += porcentage\n",
    "    intervals.append(accumulated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action(number: float):\n",
    "    output = 0\n",
    "    while number > intervals[output]:\n",
    "        output += 1\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_levestein = []\n",
    "originals = []\n",
    "for word in random.sample(words, num_samples):\n",
    "    curr_word = \"\"\n",
    "    curr_char_idx = 0\n",
    "    while curr_char_idx != len(word):\n",
    "        action = get_action(random.uniform(0, 1))\n",
    "        # Delete char\n",
    "        if action == 0:\n",
    "            curr_char_idx += 1\n",
    "        # Add random char\n",
    "        elif action == 1:\n",
    "            random_char = random.choice(string.ascii_letters)\n",
    "            curr_word += random_char\n",
    "        # Replace char\n",
    "        elif action == 2:\n",
    "            random_char = random.choice(string.ascii_letters)\n",
    "            curr_word += random_char\n",
    "            curr_char_idx += 1\n",
    "        # Maintain char\n",
    "        elif action == 3:\n",
    "            curr_word += word[curr_char_idx]\n",
    "            curr_char_idx += 1\n",
    "    words_levestein.append(curr_word)\n",
    "    originals.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 1\n",
    "words_levestein[index], originals[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = []\n",
    "for word in words_levestein[:100]:\n",
    "    print(f\"Checking {word}\")\n",
    "    for dist in range(4):\n",
    "        if not check_levestein(word, dist):\n",
    "            print(f\"Failed for {word} and {dist}\")\n",
    "            errors.append((word, dist))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ita",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
