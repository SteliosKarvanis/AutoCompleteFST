{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "import subprocess\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "with open(\"data/american-english-sorted\", 'r') as f:\n",
    "    for word in f.readlines():\n",
    "        words.append(word.replace('\\n', ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate random prefixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefixes = []\n",
    "for word in random.sample(words, num_samples):\n",
    "    while(len(word) < 2):\n",
    "        word = random.choice(words)\n",
    "    rand_int = random.randint(1, len(word)-1)\n",
    "    prefix = word[:rand_int]\n",
    "    prefixes.append(prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save prefix examples to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"tmp\", exist_ok=True)\n",
    "with open(\"tmp/examples.txt\", \"w\") as f:\n",
    "    for x in prefixes:\n",
    "        f.write(x)\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ha', 'pos', 'Bou', 'whitewall', 'w']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefixes[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate random prefixes with a fix length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random(prefix_len: int):\n",
    "    while True:\n",
    "        word = random.choice(words)\n",
    "        if len(word) >= prefix_len:\n",
    "            break\n",
    "    return word[:prefix_len]\n",
    "\n",
    "def get_result(prefix: str):\n",
    "    return [x for x in words if x.startswith(prefix)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plut\n",
      "['Plutarch', \"Plutarch's\", 'Pluto', \"Pluto's\"]\n"
     ]
    }
   ],
   "source": [
    "prefix = get_random(prefix_len=4)\n",
    "results = get_result(prefix)\n",
    "print(prefix) \n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cpp_results(text: str):\n",
    "    os.chdir(\"bin\")\n",
    "    program_path = './autocomplete'\n",
    "    arguments = [text]\n",
    "    subprocess.run([program_path] + arguments, text=True, capture_output=True)\n",
    "    with open(\"../output_files/output_autocomplete.txt\", 'r') as f:\n",
    "        result = [x.replace('\\n', '') for x in f.readlines()]\n",
    "    os.chdir(\"..\")\n",
    "    return result\n",
    "\n",
    "def get_expected_results(text):\n",
    "    return [x for x in words if x.startswith(text)]\n",
    "\n",
    "def check_autocomplete(text):\n",
    "    return get_cpp_results(text) == get_expected_results(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_autocomplete('lamasae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking ha\n",
      "Checking pos\n",
      "Checking Bou\n",
      "Checking whitewall\n",
      "Checking w\n",
      "Checking K\n",
      "Checking B\n",
      "Checking fragme\n",
      "Checking fixi\n",
      "Checking conclu\n",
      "Checking Ta\n",
      "Checking tourn\n",
      "Checking str\n",
      "Checking misconstruc\n",
      "Checking c\n",
      "Checking rile\n",
      "Checking sab\n",
      "Checking c\n",
      "Checking impious\n",
      "Checking stilln\n"
     ]
    }
   ],
   "source": [
    "for prefix in prefixes[:20]:\n",
    "    print(f\"Checking {prefix}\")\n",
    "    if not check_autocomplete(prefix):\n",
    "        raise Exception(f\"Failed for {prefix}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bin_search_results(text: str):\n",
    "    os.chdir(\"bin\")\n",
    "    program_path = './binary_search'\n",
    "    arguments = [text]\n",
    "    subprocess.run([program_path] + arguments)\n",
    "    with open(\"../output_files/output_bin_search.txt\", 'r') as f:\n",
    "        result = [x.replace('\\n', '') for x in f.readlines()]\n",
    "    os.chdir(\"..\")\n",
    "    return result\n",
    "\n",
    "def check_bin_search(text):\n",
    "    return get_bin_search_results(text) == get_expected_results(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking ha\n",
      "Checking pos\n",
      "Checking Bou\n",
      "Checking whitewall\n",
      "Checking w\n",
      "Checking K\n",
      "Checking B\n",
      "Checking fragme\n",
      "Checking fixi\n",
      "Checking conclu\n",
      "Checking Ta\n",
      "Checking tourn\n",
      "Checking str\n",
      "Checking misconstruc\n",
      "Checking c\n",
      "Checking rile\n",
      "Checking sab\n",
      "Checking c\n",
      "Checking impious\n",
      "Checking stilln\n",
      "Checking putati\n",
      "Checking bagatelle'\n",
      "Checking b\n",
      "Checking uncertain\n",
      "Checking stipulati\n",
      "Checking t\n",
      "Checking mastermindi\n",
      "Checking bullf\n",
      "Checking biol\n",
      "Checking Sp\n",
      "Checking feveris\n",
      "Checking an\n",
      "Checking jus\n",
      "Checking mis\n",
      "Checking Ashley'\n",
      "Checking burrito\n",
      "Checking Knop\n",
      "Checking v\n",
      "Checking fulfill\n",
      "Checking Erla\n",
      "Checking atyp\n",
      "Checking fe\n",
      "Checking antide\n",
      "Checking jaywalke\n",
      "Checking at\n",
      "Checking scan\n",
      "Checking nymphoma\n",
      "Checking tig\n",
      "Checking footst\n",
      "Checking s\n",
      "Checking misd\n",
      "Checking diabetic\n",
      "Checking jo\n",
      "Checking crabbines\n",
      "Checking allocat\n",
      "Checking counci\n",
      "Checking dupli\n",
      "Checking tru\n",
      "Checking confi\n",
      "Checking M\n",
      "Checking A\n",
      "Checking derai\n",
      "Checking wood\n",
      "Checking bass\n",
      "Checking servo\n",
      "Checking alle\n",
      "Checking bl\n",
      "Checking Per\n",
      "Checking investment'\n",
      "Checking i\n",
      "Checking climbe\n",
      "Checking ape\n",
      "Checking trefo\n",
      "Checking ear\n",
      "Checking Ostrog\n",
      "Checking sp\n",
      "Checking qu\n",
      "Checking Asmara\n",
      "Checking definab\n",
      "Checking dissip\n",
      "Checking vel\n",
      "Checking geol\n",
      "Checking do\n",
      "Checking rapi\n",
      "Checking restructu\n",
      "Checking S\n",
      "Checking Car\n",
      "Checking yaws'\n",
      "Checking crib\n",
      "Checking filmi\n",
      "Checking Morm\n",
      "Checking defia\n",
      "Checking hollow\n",
      "Checking ta\n",
      "Checking treachery'\n",
      "Checking inebri\n",
      "Checking enur\n",
      "Checking sub\n",
      "Checking Weissmu\n",
      "Checking reus\n",
      "Checking l\n",
      "Checking coronati\n",
      "Checking manacl\n",
      "Checking VHF'\n",
      "Checking br\n",
      "Checking comm\n",
      "Checking document\n",
      "Checking repu\n",
      "Checking thundersho\n",
      "Checking An\n",
      "Checking pru\n",
      "Checking Mu\n",
      "Checking cheap\n",
      "Checking b\n",
      "Checking insiste\n",
      "Checking over\n",
      "Checking Do\n",
      "Checking b\n",
      "Checking belittl\n",
      "Checking malfunct\n",
      "Checking b\n",
      "Checking un\n",
      "Checking cloisterin\n",
      "Checking te\n",
      "Checking r\n",
      "Checking exhortat\n",
      "Checking opiat\n",
      "Checking swe\n",
      "Checking sn\n",
      "Checking d\n",
      "Checking Cel\n",
      "Checking w\n",
      "Checking Decemb\n",
      "Checking ad\n",
      "Checking Pakistan\n",
      "Checking s\n",
      "Checking conscie\n",
      "Checking l\n",
      "Checking pl\n",
      "Checking futu\n",
      "Checking ha\n",
      "Checking unl\n",
      "Checking rememberi\n",
      "Checking d\n",
      "Checking Mag\n",
      "Checking carnat\n",
      "Checking widow\n",
      "Checking lanki\n",
      "Checking unripe\n",
      "Checking Ben\n",
      "Checking disillusionment'\n",
      "Checking incense\n",
      "Checking Mendeli\n",
      "Checking Arjun\n",
      "Checking cro\n",
      "Checking guilt\n",
      "Checking haberdas\n",
      "Checking ascend\n",
      "Checking mopp\n",
      "Checking suc\n",
      "Checking vinegar\n",
      "Checking Ran\n",
      "Checking co\n",
      "Checking pr\n",
      "Checking s\n",
      "Checking Coo\n",
      "Checking Tangs\n",
      "Checking u\n",
      "Checking co\n",
      "Checking U\n",
      "Checking nea\n",
      "Checking ringtone\n",
      "Checking tri\n",
      "Checking belti\n",
      "Checking reve\n",
      "Checking r\n",
      "Checking p\n",
      "Checking Madden\n",
      "Checking Chukchi'\n",
      "Checking disq\n",
      "Checking han\n",
      "Checking Congr\n",
      "Checking rec\n",
      "Checking s\n",
      "Checking mini\n",
      "Checking pureness\n",
      "Checking Filipi\n",
      "Checking o\n",
      "Checking psychoa\n",
      "Checking Zap\n",
      "Checking selle\n",
      "Checking T\n",
      "Checking outgrowth\n",
      "Checking past\n",
      "Checking catc\n",
      "Checking b\n",
      "Checking la\n",
      "Checking repr\n",
      "Checking tu\n",
      "Checking M\n"
     ]
    }
   ],
   "source": [
    "for prefix in prefixes[:200]:\n",
    "    print(f\"Checking {prefix}\")\n",
    "    if not check_bin_search(prefix):\n",
    "        raise Exception(f\"Failed for {prefix}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Levestein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textdistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieve_levestein_dist = textdistance.levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def levestein(text, max_dist):\n",
    "    output = []\n",
    "    for word in words:\n",
    "        dist = retrieve_levestein_dist(word, text)\n",
    "        if dist <= max_dist:\n",
    "            output.append(word)\n",
    "    return output\n",
    "\n",
    "def get_cpp_levestein_results(text: str, dist: int):\n",
    "    os.chdir(\"bin\")\n",
    "    program_path = './levestein'\n",
    "    arguments = [text, str(dist)]\n",
    "    subprocess.run([program_path] + arguments, text=True, capture_output=True)\n",
    "    with open(\"../output_files/output_levestein.txt\", 'r') as f:\n",
    "        result = [x.replace('\\n', '') for x in f.readlines()]\n",
    "    result.sort()\n",
    "    os.chdir(\"..\")\n",
    "    return result\n",
    "\n",
    "def check_levestein(text, dist):\n",
    "    return get_cpp_levestein_results(text, dist) == levestein(text, dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AA', 'AAA', 'AMA', 'FAA']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_cpp_levestein_results(\"AAA\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AA', 'AAA', 'AMA', 'FAA']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "levestein(\"AAA\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_levestein(\"AAA\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [delete , add, replace, maintain]\n",
    "maintain = 0.9\n",
    "others = (1 - maintain)/3\n",
    "porcentages = [others, others, others, maintain]\n",
    "assert sum(porcentages) == 1\n",
    "accumulated = 0\n",
    "intervals = []\n",
    "for porcentage in porcentages:\n",
    "    accumulated += porcentage\n",
    "    intervals.append(accumulated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action(number: float):\n",
    "    output = 0\n",
    "    while number > intervals[output]:\n",
    "        output += 1\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_levestein = []\n",
    "originals = []\n",
    "for word in random.sample(words, num_samples):\n",
    "    curr_word = \"\"\n",
    "    curr_char_idx = 0\n",
    "    while curr_char_idx != len(word):\n",
    "        action = get_action(random.uniform(0, 1))\n",
    "        # Delete char\n",
    "        if action == 0:\n",
    "            curr_char_idx += 1\n",
    "        # Add random char\n",
    "        elif action == 1:\n",
    "            random_char = random.choice(string.ascii_letters)\n",
    "            curr_word += random_char\n",
    "        # Replace char\n",
    "        elif action == 2:\n",
    "            random_char = random.choice(string.ascii_letters)\n",
    "            curr_word += random_char\n",
    "            curr_char_idx += 1\n",
    "        # Maintain char\n",
    "        elif action == 3:\n",
    "            curr_word += word[curr_char_idx]\n",
    "            curr_char_idx += 1\n",
    "    words_levestein.append(curr_word)\n",
    "    originals.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('upraised', 'upraised')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = 1\n",
    "words_levestein[index], originals[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking bassinets\n",
      "Checking upraised\n",
      "Checking eJcantaoionX\n",
      "Checking narcisistic\n",
      "Checking peacocks\n",
      "Checking GilEore's\n",
      "Checking Vindemiatrix's\n",
      "Checking typeset\n",
      "Checking refffirms\n",
      "Checking drenching\n"
     ]
    }
   ],
   "source": [
    "errors = []\n",
    "for word in words_levestein[:100]:\n",
    "    print(f\"Checking {word}\")\n",
    "    for dist in range(4):\n",
    "        if not check_levestein(word, dist):\n",
    "            print(f\"Failed for {word} and {dist}\")\n",
    "            errors.append((word, dist))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ita",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
